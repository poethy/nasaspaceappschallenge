"""
Streamlit app para detecci√≥n de exoplanetas:
- Subir CSV con datos de Kepler
- Preprocesar autom√°ticamente
- Generar caracter√≠sticas
- Predecir con modelo entrenado
- Mostrar gr√°ficas y an√°lisis
"""
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
import io
import subprocess

# Configurar matplotlib para espa√±ol
plt.rcParams['font.size'] = 10
sns.set_palette("husl")

# Asegurarse que src est√© en path
sys.path.append(str(Path(__file__).resolve().parents[1] / "src"))

# Importar funciones de preprocesamiento
from preprocessing import detect_table_start, parse_table_from, to_numeric_columns, impute_median
from feature_engineering import basic_feature_engineering

st.set_page_config(page_title="ü™ê Exoplanet Detector", layout="wide", page_icon="ü™ê")

# Header din√°mico seg√∫n misi√≥n (se actualizar√° despu√©s del sidebar)
# Temporalmente vac√≠o, se llenar√° despu√©s
mission_placeholder = st.empty()

# Sidebar con informaci√≥n y selector de misi√≥n
with st.sidebar:
    st.header("üöÄ Selecciona la Misi√≥n")
    
    mission = st.radio(
        "¬øQu√© misi√≥n quieres analizar?",
        options=["KEPLER", "TESS (TOI)", "K2"],
        help="Cada misi√≥n tiene un modelo especializado entrenado con sus datos espec√≠ficos"
    )
    
    st.markdown("---")
    
    # Informaci√≥n seg√∫n la misi√≥n
    mission_info = {
        "KEPLER": {
            "name": "Kepler",
            "launched": "2009",
            "planets": "~2,800",
            "columns": "kepid, koi_*",
            "icon": "üî≠"
        },
        "TESS (TOI)": {
            "name": "TESS",
            "launched": "2018",
            "planets": "~400+",
            "columns": "toi, tid, pl_*",
            "icon": "üõ∞Ô∏è"
        },
        "K2": {
            "name": "K2",
            "launched": "2014",
            "planets": "~500",
            "columns": "pl_name, disposition",
            "icon": "üåå"
        }
    }
    
    info = mission_info[mission]
    st.header(f"{info['icon']} {info['name']}")
    st.markdown(f"""
    **Lanzamiento:** {info['launched']}  
    **Exoplanetas:** {info['planets']}  
    **Columnas clave:** `{info['columns']}`
    """)
    
    st.markdown("---")
    st.header("‚ÑπÔ∏è Instrucciones")
    st.markdown("""
    1. Selecciona la misi√≥n arriba
    2. Sube el CSV correspondiente
    3. El sistema procesar√° autom√°ticamente
    4. Predice: **Confirmado**, **Candidato** o **Falso Positivo**
    
    **Modelo:** LightGBM  
    **Precisi√≥n:** ~94-95%
    """)
    
    st.markdown("---")
    st.markdown("**NASA Space Apps Challenge 2025 | Equipo: NoLit Developers**")

# Actualizar header seg√∫n misi√≥n seleccionada
with mission_placeholder.container():
    st.title(f"{info['icon']} Detector de Exoplanetas - {info['name']}")
    st.markdown(f"### Clasificador especializado para la misi√≥n {info['name']}")
    st.markdown("---")

# Configuraci√≥n seg√∫n misi√≥n
mission_config = {
    "KEPLER": {
        "model_path": "models/exoplanet_model_kepler.joblib",
        "dataset_example": "cumulativeKEPLER.csv",
        "id_col": "kepid",
        "name_col": "kepoi_name"
    },
    "TESS (TOI)": {
        "model_path": "models/exoplanet_model_tess.joblib",
        "dataset_example": "cumulativeTOI.csv",
        "id_col": "tid",
        "name_col": "toi"
    },
    "K2": {
        "model_path": "models/exoplanet_model_k2.joblib",
        "dataset_example": "cumulativeK2.csv",
        "id_col": "hostname",
        "name_col": "pl_name"
    }
}

config = mission_config[mission]

# Upload section
st.header("üì§ 1. Subir Dataset")
uploaded = st.file_uploader(
    f"Arrastra o selecciona un archivo CSV de {info['name']}",
    type=['csv'],
    help=f"El archivo debe ser del cat√°logo {info['name']}. Ejemplo: {config['dataset_example']}"
)

if not uploaded:
    st.info("üëÜ Por favor, sube un archivo CSV para comenzar el an√°lisis.")
    st.stop()

# Procesamiento autom√°tico
with st.spinner("üîÑ Procesando datos..."):
    try:
        # Detectar inicio de tabla
        temp_file = f"/tmp/uploaded_{uploaded.name}"
        with open(temp_file, "wb") as f:
            f.write(uploaded.getbuffer())
        
        start_idx = detect_table_start(temp_file)
        if start_idx is not None:
            df_pd, df_raw = parse_table_from(temp_file, start_idx)
            df = to_numeric_columns(df_pd)
        else:
            df = pd.read_csv(uploaded)
        
        # Aplicar preprocesamiento
        df = impute_median(df)
        
        # Feature engineering
        df = basic_feature_engineering(df)
        
        st.success("‚úÖ Datos procesados exitosamente!")
        
    except Exception as e:
        st.error(f"‚ùå Error al procesar el archivo: {str(e)}")
        st.stop()

# Mostrar estad√≠sticas del dataset
st.header("üìä 2. Estad√≠sticas del Dataset")
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("Total de Objetos", len(df))
with col2:
    st.metric("Caracter√≠sticas", len(df.columns))
with col3:
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    st.metric("Columnas Num√©ricas", len(numeric_cols))
with col4:
    if 'target_label' in df.columns:
        st.metric("Etiquetas √önicas", df['target_label'].nunique())
    else:
        st.metric("Valores Nulos", df.isnull().sum().sum())

# Preview de datos
with st.expander("üëÅÔ∏è Ver muestra de datos (primeras 10 filas)"):
    st.dataframe(df.head(10), use_container_width=True)

# Verificar modelo seg√∫n misi√≥n
model_path = Path(config["model_path"])
if not model_path.exists():
    st.error(f"‚ùå No se encontr√≥ modelo para {info['name']}. Entrenando modelo autom√°ticamente...")
    
    # Entrenar modelo autom√°ticamente
    with st.spinner(f"ü§ñ Entrenando modelo especializado para {info['name']}... Esto puede tomar unos minutos."):
        try:
            mission_key = mission.replace(" (TOI)", "").lower()
            result = subprocess.run(
                ["python", "run.py", "train_all"],
                capture_output=True,
                text=True,
                timeout=600
            )
            if result.returncode == 0:
                st.success(f"‚úÖ Modelo de {info['name']} entrenado exitosamente!")
                st.rerun()
            else:
                st.error(f"Error al entrenar modelo: {result.stderr}")
                st.stop()
        except Exception as e:
            st.error(f"Error al entrenar modelo: {str(e)}")
            st.stop()

# Cargar modelo
@st.cache_resource
def load_model(model_file):
    model = joblib.load(str(model_file))
    scaler = joblib.load(str(model_file).replace('.joblib', '.scaler.joblib'))
    features = joblib.load(str(model_file).replace('.joblib', '.features.joblib'))
    return model, scaler, features

model, scaler, features = load_model(model_path)

# Predicciones
st.header("üîÆ 3. Predicciones del Modelo")

with st.spinner("ü§ñ Generando predicciones..."):
    # Preparar datos
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    X = df[numeric_cols].copy()
    
    # Guardar labels si existen
    has_labels = 'target_label' in X.columns
    if has_labels:
        y_true = X['target_label'].values
        X = X.drop(columns=['target_label'])
    
    # Preparar matriz de features
    X_model = pd.DataFrame(0, index=X.index, columns=features)
    for c in X.columns:
        if c in X_model.columns:
            X_model[c] = X[c].values
    
    # Escalar y predecir
    X_scaled = scaler.transform(X_model.values)
    probs = model.predict_proba(X_scaled)
    predictions = model.predict(X_scaled)
    
    # Crear DataFrame de resultados
    labels = {0: 'Falso Positivo', 1: 'Candidato', 2: 'Confirmado'}
    df_predictions = pd.DataFrame({
        'Predicci√≥n': [labels[p] for p in predictions],
        'Prob. Falso Positivo': probs[:, 0],
        'Prob. Candidato': probs[:, 1],
        'Prob. Confirmado': probs[:, 2]
    })

st.success(f"‚úÖ {len(predictions)} predicciones generadas!")

# An√°lisis de descubrimientos
num_confirmados = (predictions == 2).sum()
num_candidatos = (predictions == 1).sum()
num_exoplanetas = num_confirmados + num_candidatos
num_falsos = (predictions == 0).sum()

# M√©tricas destacadas de descubrimientos
st.markdown("### üåü Descubrimientos de Exoplanetas")
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric(
        "ü™ê Exoplanetas Totales", 
        num_exoplanetas,
        delta=f"{(num_exoplanetas/len(predictions)*100):.1f}%",
        help="Candidatos + Confirmados"
    )
with col2:
    st.metric(
        "‚úÖ Confirmados", 
        num_confirmados,
        delta=f"{(num_confirmados/len(predictions)*100):.1f}%"
    )
with col3:
    st.metric(
        "üîç Candidatos", 
        num_candidatos,
        delta=f"{(num_candidatos/len(predictions)*100):.1f}%"
    )
with col4:
    st.metric(
        "‚ùå Falsos Positivos", 
        num_falsos,
        delta=f"-{(num_falsos/len(predictions)*100):.1f}%",
        delta_color="inverse"
    )

if num_exoplanetas > 0:
    st.success(f"üéâ **¬°El modelo ha identificado {num_exoplanetas} posibles exoplanetas en tu dataset!**")
    
    # Filtrar exoplanetas de alta confianza
    umbral_confianza = 0.7
    exoplanetas_alta_confianza = (
        ((predictions == 2) & (probs[:, 2] >= umbral_confianza)) |
        ((predictions == 1) & (probs[:, 1] >= umbral_confianza))
    )
    num_alta_confianza = exoplanetas_alta_confianza.sum()
    
    if num_alta_confianza > 0:
        st.info(f"üåü **{num_alta_confianza} exoplanetas tienen confianza ‚â• {umbral_confianza*100:.0f}%** - ¬°Estos son los descubrimientos m√°s prometedores!")
else:
    st.warning("‚ö†Ô∏è No se identificaron exoplanetas candidatos o confirmados en este dataset.")

st.markdown("---")

# Mostrar distribuci√≥n de predicciones
col1, col2 = st.columns(2)

with col1:
    st.subheader("üìà Distribuci√≥n de Predicciones")
    fig, ax = plt.subplots(figsize=(8, 6))
    pred_counts = pd.Series(predictions).map(labels).value_counts()
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    ax.bar(pred_counts.index, pred_counts.values, color=colors)
    ax.set_xlabel('Clasificaci√≥n', fontsize=12, fontweight='bold')
    ax.set_ylabel('Cantidad', fontsize=12, fontweight='bold')
    ax.set_title('Distribuci√≥n de Clasificaciones', fontsize=14, fontweight='bold')
    plt.xticks(rotation=15)
    for i, v in enumerate(pred_counts.values):
        ax.text(i, v + 0.5, str(v), ha='center', va='bottom', fontweight='bold')
    st.pyplot(fig)
    plt.close()

with col2:
    st.subheader("üéØ Distribuci√≥n de Probabilidades")
    fig, ax = plt.subplots(figsize=(8, 6))
    max_probs = probs.max(axis=1)
    ax.hist(max_probs, bins=30, color='#45B7D1', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Probabilidad M√°xima', fontsize=12, fontweight='bold')
    ax.set_ylabel('Frecuencia', fontsize=12, fontweight='bold')
    ax.set_title('Confianza de las Predicciones', fontsize=14, fontweight='bold')
    ax.axvline(max_probs.mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {max_probs.mean():.3f}')
    ax.legend()
    st.pyplot(fig)
    plt.close()

# Importancia de caracter√≠sticas
st.header("üìä 4. An√°lisis del Modelo")

col1, col2 = st.columns(2)

with col1:
    st.subheader("üîù Top 15 Caracter√≠sticas Importantes")
    if hasattr(model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'Caracter√≠stica': features,
            'Importancia': model.feature_importances_
        }).sort_values('Importancia', ascending=False).head(15)
        
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.barh(range(len(importance_df)), importance_df['Importancia'], color='#FF6B6B')
        ax.set_yticks(range(len(importance_df)))
        ax.set_yticklabels(importance_df['Caracter√≠stica'], fontsize=9)
        ax.set_xlabel('Importancia', fontsize=12, fontweight='bold')
        ax.set_title('Caracter√≠sticas M√°s Relevantes', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        st.pyplot(fig)
        plt.close()
    else:
        st.info("El modelo no proporciona importancia de caracter√≠sticas")

with col2:
    st.subheader("üìâ Matriz de Correlaci√≥n (Top Features)")
    if hasattr(model, 'feature_importances_'):
        top_features = importance_df['Caracter√≠stica'].head(10).tolist()
        correlation_data = X_model[top_features].corr()
        
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(correlation_data, annot=True, fmt='.2f', cmap='coolwarm', 
                    center=0, ax=ax, cbar_kws={'label': 'Correlaci√≥n'})
        ax.set_title('Correlaci√≥n entre Top Features', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45, ha='right', fontsize=8)
        plt.yticks(fontsize=8)
        st.pyplot(fig)
        plt.close()

# Matriz de confusi√≥n si hay labels
if has_labels:
    st.subheader("üéØ Matriz de Confusi√≥n")
    from sklearn.metrics import confusion_matrix, classification_report
    
    # Filtrar solo las filas con labels v√°lidos
    valid_idx = (y_true >= 0) & (y_true <= 2)
    y_true_valid = y_true[valid_idx]
    y_pred_valid = predictions[valid_idx]
    
    if len(y_true_valid) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            cm = confusion_matrix(y_true_valid, y_pred_valid)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                        xticklabels=list(labels.values()),
                        yticklabels=list(labels.values()),
                        ax=ax)
            ax.set_ylabel('Real', fontsize=12, fontweight='bold')
            ax.set_xlabel('Predicci√≥n', fontsize=12, fontweight='bold')
            ax.set_title('Matriz de Confusi√≥n', fontsize=14, fontweight='bold')
            st.pyplot(fig)
            plt.close()
        
        with col2:
            st.subheader("üìã Reporte de Clasificaci√≥n")
            report = classification_report(y_true_valid, y_pred_valid, 
                                          target_names=list(labels.values()),
                                          output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df.style.format("{:.3f}"), use_container_width=True)

# Tabla de exoplanetas descubiertos
st.header("üåü 5. Exoplanetas Descubiertos")

if num_exoplanetas > 0:
    # Filtrar solo exoplanetas (candidatos + confirmados)
    mask_exoplanetas = (predictions == 1) | (predictions == 2)
    
    # Crear DataFrame de exoplanetas
    df_exoplanetas = df.reset_index(drop=True)[mask_exoplanetas].copy()
    df_pred_exoplanetas = df_predictions[mask_exoplanetas].copy()
    
    # Columnas a mostrar seg√∫n la misi√≥n
    if mission == "KEPLER":
        columnas_exoplanetas = [
            'kepid', 'kepoi_name', 'kepler_name',
            'Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato',
            'koi_period', 'koi_depth', 'koi_duration',
            'koi_prad', 'koi_teq', 'koi_insol',
            'koi_srad', 'koi_steff',
            'koi_model_snr', 'koi_score'
        ]
    elif mission == "TESS (TOI)":
        columnas_exoplanetas = [
            'tid', 'toi',
            'Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato',
            'pl_orbper', 'pl_trandep', 'pl_trandur',
            'pl_rade', 'pl_eqt', 'pl_insol',
            'st_rad', 'st_teff',
            'pl_dens', 'tfopwg_disp'
        ]
    else:  # K2
        columnas_exoplanetas = [
            'hostname', 'pl_name',
            'Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato',
            'pl_orbper', 'pl_trandep', 'pl_trandur',
            'pl_rade', 'pl_eqt', 'pl_insol',
            'st_rad', 'st_teff',
            'pl_dens', 'disposition'
        ]
    
    # Combinar datos
    exoplanetas_completo = pd.concat([
        df_exoplanetas.reset_index(drop=True),
        df_pred_exoplanetas.reset_index(drop=True)
    ], axis=1)
    
    # Filtrar columnas disponibles
    cols_disponibles = [col for col in columnas_exoplanetas if col in exoplanetas_completo.columns]
    
    # Asegurar que las columnas de identificaci√≥n est√©n incluidas
    id_cols_needed = []
    if mission == "KEPLER":
        id_cols_needed = ['kepid', 'kepoi_name', 'kepler_name']
    elif mission == "TESS (TOI)":
        id_cols_needed = ['tid', 'toi']
    else:  # K2
        id_cols_needed = ['hostname', 'pl_name']
    
    # Agregar columnas de ID que existan y no est√©n ya en la lista
    for id_col in id_cols_needed:
        if id_col in exoplanetas_completo.columns and id_col not in cols_disponibles:
            cols_disponibles.insert(0, id_col)
    
    if not cols_disponibles:
        cols_disponibles = list(exoplanetas_completo.columns[:15])
    
    exoplanetas_mostrar = exoplanetas_completo[cols_disponibles].copy()
    
    # Ordenar por probabilidad de confirmado (descendente)
    if 'Prob. Confirmado' in exoplanetas_mostrar.columns:
        exoplanetas_mostrar = exoplanetas_mostrar.sort_values('Prob. Confirmado', ascending=False)
    
    st.markdown(f"""
    ### üìä Lista de {len(exoplanetas_mostrar)} Exoplanetas Identificados
    
    **Interpretaci√≥n:**
    - ‚úÖ **Confirmado**: El modelo tiene alta confianza de que es un exoplaneta real
    - üîç **Candidato**: Probable exoplaneta que requiere confirmaci√≥n adicional
    - üéØ **Probabilidad**: Mayor probabilidad = Mayor confianza del modelo
    """)
    
    # Tabs para diferentes vistas
    tab1, tab2 = st.tabs(["üìã Tabla Completa", "üèÜ Top 10 Confianza"])
    
    with tab1:
        st.dataframe(
            exoplanetas_mostrar.style.format({
                'Prob. Confirmado': '{:.3f}',
                'Prob. Candidato': '{:.3f}',
            }, na_rep='-'),
            width='stretch',
            height=400
        )
    
    with tab2:
        st.markdown("### üèÜ Top 10 Exoplanetas con Mayor Confianza")
        top10 = exoplanetas_mostrar.head(10)
        
        for rank, (idx, row) in enumerate(top10.iterrows(), start=1):
            # Identificador din√°mico seg√∫n misi√≥n
            if mission == "KEPLER":
                # Intentar diferentes columnas de identificaci√≥n
                if 'kepoi_name' in row and pd.notna(row['kepoi_name']) and row['kepoi_name'] != '':
                    obj_id = row['kepoi_name']
                elif 'kepid' in row and pd.notna(row['kepid']):
                    obj_id = f"KepID-{int(row['kepid'])}"
                elif 'kepler_name' in row and pd.notna(row['kepler_name']) and row['kepler_name'] != '':
                    obj_id = row['kepler_name']
                else:
                    obj_id = f"Exoplaneta {rank}"
            elif mission == "TESS (TOI)":
                if 'toi' in row and pd.notna(row['toi']) and row['toi'] != '':
                    obj_id = f"TOI-{row['toi']}"
                elif 'tid' in row and pd.notna(row['tid']):
                    obj_id = f"TIC-{int(row['tid'])}"
                else:
                    obj_id = f"Exoplaneta {rank}"
            else:  # K2
                if 'pl_name' in row and pd.notna(row['pl_name']) and row['pl_name'] != '':
                    obj_id = row['pl_name']
                elif 'hostname' in row and pd.notna(row['hostname']) and row['hostname'] != '':
                    obj_id = row['hostname']
                else:
                    obj_id = f"Exoplaneta {rank}"
            
            with st.expander(f"ü™ê #{rank} - {obj_id} - {row['Predicci√≥n']}"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Confianza", f"{row['Prob. Confirmado']*100:.1f}%")
                    # Per√≠odo orbital (diferentes columnas por misi√≥n)
                    period_col = 'koi_period' if mission == "KEPLER" else 'pl_orbper'
                    if period_col in row and pd.notna(row[period_col]):
                        st.metric("Per√≠odo Orbital", f"{row[period_col]:.2f} d√≠as")
                
                with col2:
                    # Radio del planeta
                    rad_col = 'koi_prad' if mission == "KEPLER" else 'pl_rade'
                    if rad_col in row and pd.notna(row[rad_col]):
                        st.metric("Radio Planeta", f"{row[rad_col]:.2f} R‚äï")
                    # Temperatura
                    temp_col = 'koi_teq' if mission == "KEPLER" else 'pl_eqt'
                    if temp_col in row and pd.notna(row[temp_col]):
                        st.metric("Temperatura", f"{row[temp_col]:.0f} K")
                
                with col3:
                    # Profundidad del tr√°nsito
                    depth_col = 'koi_depth' if mission == "KEPLER" else 'pl_trandep'
                    if depth_col in row and pd.notna(row[depth_col]):
                        st.metric("Profundidad Tr√°nsito", f"{row[depth_col]:.2f} ppm")
                    # Radio estelar
                    srad_col = 'koi_srad' if mission == "KEPLER" else 'st_rad'
                    if srad_col in row and pd.notna(row[srad_col]):
                        st.metric("Radio Estelar", f"{row[srad_col]:.2f} R‚òâ")
    
    # Bot√≥n de descarga de exoplanetas
    st.markdown("---")
    csv_exoplanetas = exoplanetas_mostrar.to_csv(index=False)
    st.download_button(
        label="üì• Descargar solo exoplanetas descubiertos (CSV)",
        data=csv_exoplanetas,
        file_name="exoplanetas_descubiertos.csv",
        mime="text/csv",
        use_container_width=True,
        help=f"Descarga solo los {len(exoplanetas_mostrar)} exoplanetas identificados"
    )
else:
    st.info("No se identificaron exoplanetas en este dataset. Todos los objetos fueron clasificados como falsos positivos.")

st.markdown("---")

# Tabla de resultados completos
st.header("üìã 6. Resultados Detallados (Todos los Objetos)")

# Crear DataFrame completo con todas las columnas
result_df_complete = pd.concat([
    df.reset_index(drop=True),
    df_predictions.reset_index(drop=True)
], axis=1)

# Definir columnas relevantes para el usuario
columnas_importantes = [
    # Identificaci√≥n
    'kepid', 'kepoi_name', 'kepler_name',
    # Predicciones (siempre al inicio)
    'Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato', 'Prob. Falso Positivo',
    # Caracter√≠sticas orbitales
    'koi_period', 'koi_duration', 'koi_time0bk',
    # Caracter√≠sticas de tr√°nsito (picos de luz)
    'koi_depth', 'koi_ror', 'koi_impact',
    # Caracter√≠sticas del planeta
    'koi_prad', 'koi_teq', 'koi_insol',
    # Caracter√≠sticas de la estrella
    'koi_srad', 'koi_steff', 'koi_slogg',
    # SNR y calidad de datos
    'koi_model_snr', 'koi_tce_plnt_num',
    # Disposici√≥n original si existe
    'koi_disposition', 'koi_pdisposition', 'koi_score'
]

# Filtrar solo las columnas que existen en el DataFrame
columnas_disponibles = [col for col in columnas_importantes if col in result_df_complete.columns]

# Si tenemos predicciones, moverlas al inicio
if 'Predicci√≥n' in columnas_disponibles:
    pred_cols = ['Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato', 'Prob. Falso Positivo']
    pred_cols = [col for col in pred_cols if col in columnas_disponibles]
    otras_cols = [col for col in columnas_disponibles if col not in pred_cols]
    columnas_disponibles = pred_cols + otras_cols

# Crear DataFrame filtrado
if columnas_disponibles:
    result_df_display = result_df_complete[columnas_disponibles].copy()
else:
    # Si no encontramos columnas espec√≠ficas, mostrar las num√©ricas m√°s relevantes
    numeric_cols = result_df_complete.select_dtypes(include=[np.number]).columns[:15].tolist()
    pred_cols = ['Predicci√≥n', 'Prob. Confirmado', 'Prob. Candidato', 'Prob. Falso Positivo']
    display_cols = [col for col in pred_cols if col in result_df_complete.columns] + numeric_cols
    result_df_display = result_df_complete[display_cols]

st.markdown("""
**Columnas mostradas:**
- üéØ **Predicciones**: Clasificaci√≥n y probabilidades del modelo
- üåç **Caracter√≠sticas del planeta**: Radio (koi_prad), temperatura (koi_teq)
- üîÜ **Tr√°nsito de luz**: Profundidad (koi_depth), duraci√≥n del tr√°nsito
- ‚≠ê **Caracter√≠sticas estelares**: Radio estelar, temperatura efectiva
- üìä **M√©tricas de calidad**: SNR, score de confianza
""")

# Mostrar con formato mejorado
st.dataframe(
    result_df_display.head(50).style.format({
        'Prob. Confirmado': '{:.3f}',
        'Prob. Candidato': '{:.3f}',
        'Prob. Falso Positivo': '{:.3f}',
    }, na_rep='-'),
    use_container_width=True,
    height=400
)

# Descarga de resultados
st.header("üíæ 7. Descargar Resultados")

col1, col2 = st.columns(2)

with col1:
    # Descargar solo columnas relevantes
    csv_filtrado = result_df_display.to_csv(index=False)
    st.download_button(
        label="üì• Descargar resultados filtrados (CSV)",
        data=csv_filtrado,
        file_name="exoplanet_predictions_filtrado.csv",
        mime="text/csv",
        use_container_width=True,
        help="Descarga solo las columnas m√°s relevantes mostradas en la tabla"
    )

with col2:
    # Descargar todas las columnas
    csv_completo = result_df_complete.to_csv(index=False)
    st.download_button(
        label="üì• Descargar resultados completos (CSV)",
        data=csv_completo,
        file_name="exoplanet_predictions_completo.csv",
        mime="text/csv",
        use_container_width=True,
        help="Descarga todas las columnas incluyendo caracter√≠sticas t√©cnicas"
    )

# Footer
st.markdown("---")
st.markdown("**üöÄ Desarrollado para NASA Space Apps Challenge 2025 | Equipo: NoLit Developers**")
st.markdown("---")
st.link_button("üîô Volver al Portal Principal", "https://06067336e270.ngrok-free.app/")
